{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42189075-2b3f-407f-9a2f-69b24d66535b",
   "metadata": {},
   "source": [
    "# Testing Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27700e00-69a1-4870-aeb6-42d825e0ccde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e530a33-c460-42a2-951a-25f56f78f091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import koopomics.model.model_loader as ko\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7ca3d7f-1e96-41a7-aaf3-c542e1b22bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'koopomics.model.koopmanANN' from '/Users/daviddornig/Documents/Master_Thesis/Bioinf/Code/philipp-trinh/KOOPOMICS/koopomics/model/koopmanANN.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import koopomics.model.embeddingANN as em\n",
    "import koopomics.model.koopmanANN as op\n",
    "importlib.reload(em)\n",
    "importlib.reload(op)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "728a20af-6e10-4570-afb6-390ca05c643d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ko' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(\u001b[43mko\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ko' is not defined"
     ]
    }
   ],
   "source": [
    "importlib.reload(ko)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfb4f7df-4850-4a83-865a-2f51ac58dc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = em.FF_AE([264,100,100,20], [20,100,100,264])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73866519-c876-4eec-9073-bda346b3c165",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = em.DiffeomMap([200,100,100,20],[20,100,100,200],[1,3,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "422d2826-8033-4004-98cb-7ad34b0f0ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiffeomMap(\n",
       "  (encode_NN): Sequential(\n",
       "    (0): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=100, out_features=20, bias=True)\n",
       "  )\n",
       "  (deconv_liftNN): Sequential(\n",
       "    (0): Linear(in_features=20, out_features=100, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=100, out_features=200, bias=True)\n",
       "  )\n",
       "  (deconv_outputNN): ModuleList(\n",
       "    (0-199): 200 x Sequential(\n",
       "      (0): Linear(in_features=1, out_features=3, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=3, out_features=5, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "872179ff-4bfd-4924-8499-1789ae70fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "operator_model = op.LinearizingKoop(linearizer=op.FFLinearizer([20,30,50], [50,30,20]), koop=op.InvKoop(latent_dim=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c1ec7b6-df1c-4d6a-b951-101dcf75446f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded with:\n"
     ]
    }
   ],
   "source": [
    "embedding_model = em.FF_AE([264,100,100,20], [20,100,100,264])\n",
    "operator_model = op.LinearizingKoop(linearizer=op.FFLinearizer([20,30,50], [50,30,20]), koop=op.InvKoop(latent_dim=50))\n",
    "\n",
    "LinKoopAE_model = ko.KoopmanModel(embedding=embedding_model, operator=operator_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0f42c5c-9665-49fe-a506-1636ff0b5264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KoopmanModel(\n",
       "  (embedding): FF_AE(\n",
       "    (encode): Sequential(\n",
       "      (0): Linear(in_features=264, out_features=100, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=100, out_features=20, bias=True)\n",
       "    )\n",
       "    (decode): Sequential(\n",
       "      (0): Linear(in_features=20, out_features=100, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=100, out_features=264, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (operator): LinearizingKoop(\n",
       "    (linearizer): FFLinearizer(\n",
       "      (lin_encode): Sequential(\n",
       "        (0): Linear(in_features=20, out_features=30, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=30, out_features=50, bias=True)\n",
       "      )\n",
       "      (lin_decode): Sequential(\n",
       "        (0): Linear(in_features=50, out_features=30, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=30, out_features=20, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (koop): InvKoop()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinKoopAE_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddf4bf9d-a714-4ea2-8a08-cdd2c621f361",
   "metadata": {},
   "outputs": [],
   "source": [
    "pregnancy_df = pd.read_csv('/Users/daviddornig/Documents/Master_Thesis/Bioinf/Code/philipp-trinh/KOOPOMICS/input_data/pregnancy/pregnancy_interpolated_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b08187-2e1d-4b63-879d-fdf643a3a924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a604eda-dba3-4931-815e-766682b15e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Labor onset</th>\n",
       "      <th>Gestational age (GA)/days</th>\n",
       "      <th>Gestational age (GA)/weeks</th>\n",
       "      <th>Birth GA/weeks</th>\n",
       "      <th>(+)-.alpha.-Tocopherol</th>\n",
       "      <th>(R)-2-Hydroxycaprylic acid</th>\n",
       "      <th>1,4-Dihydroxybenzene</th>\n",
       "      <th>1-Methylxanthine</th>\n",
       "      <th>...</th>\n",
       "      <th>cis-5,8,11,14,17-Eicosapentaenoic acid</th>\n",
       "      <th>cis-5-Dodecenoic acid</th>\n",
       "      <th>cis-9-Palmitoleic acid</th>\n",
       "      <th>d-LIMONENE</th>\n",
       "      <th>gamma-CEHC</th>\n",
       "      <th>gamma-Glutamylleucine</th>\n",
       "      <th>ketoisocaproic acid</th>\n",
       "      <th>p-Cresol</th>\n",
       "      <th>phenylacetylglutamine</th>\n",
       "      <th>trans-Vaccenic acid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DP01</td>\n",
       "      <td>Discovery</td>\n",
       "      <td>natural</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>38.714286</td>\n",
       "      <td>12.187246</td>\n",
       "      <td>10.075398</td>\n",
       "      <td>9.315506</td>\n",
       "      <td>10.907293</td>\n",
       "      <td>...</td>\n",
       "      <td>11.183291</td>\n",
       "      <td>10.799411</td>\n",
       "      <td>12.059483</td>\n",
       "      <td>5.643133</td>\n",
       "      <td>10.495975</td>\n",
       "      <td>12.157863</td>\n",
       "      <td>14.377687</td>\n",
       "      <td>10.635153</td>\n",
       "      <td>14.263246</td>\n",
       "      <td>11.150043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DP01</td>\n",
       "      <td>Discovery</td>\n",
       "      <td>natural</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>38.714286</td>\n",
       "      <td>12.643866</td>\n",
       "      <td>9.871381</td>\n",
       "      <td>7.523938</td>\n",
       "      <td>10.954945</td>\n",
       "      <td>...</td>\n",
       "      <td>11.018465</td>\n",
       "      <td>10.230143</td>\n",
       "      <td>11.844556</td>\n",
       "      <td>5.497642</td>\n",
       "      <td>9.847823</td>\n",
       "      <td>12.110144</td>\n",
       "      <td>14.217800</td>\n",
       "      <td>10.610887</td>\n",
       "      <td>14.001904</td>\n",
       "      <td>10.924683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DP01</td>\n",
       "      <td>Discovery</td>\n",
       "      <td>natural</td>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>38.714286</td>\n",
       "      <td>13.632884</td>\n",
       "      <td>10.025761</td>\n",
       "      <td>4.431244</td>\n",
       "      <td>9.715949</td>\n",
       "      <td>...</td>\n",
       "      <td>10.537209</td>\n",
       "      <td>9.326564</td>\n",
       "      <td>11.616709</td>\n",
       "      <td>6.736850</td>\n",
       "      <td>9.342694</td>\n",
       "      <td>12.174268</td>\n",
       "      <td>14.225116</td>\n",
       "      <td>10.848017</td>\n",
       "      <td>14.178476</td>\n",
       "      <td>10.705275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DP01</td>\n",
       "      <td>Discovery</td>\n",
       "      <td>natural</td>\n",
       "      <td>56</td>\n",
       "      <td>8</td>\n",
       "      <td>38.714286</td>\n",
       "      <td>12.125875</td>\n",
       "      <td>10.253546</td>\n",
       "      <td>5.250766</td>\n",
       "      <td>9.805404</td>\n",
       "      <td>...</td>\n",
       "      <td>10.672192</td>\n",
       "      <td>8.790673</td>\n",
       "      <td>11.874221</td>\n",
       "      <td>7.195789</td>\n",
       "      <td>10.022338</td>\n",
       "      <td>12.604769</td>\n",
       "      <td>14.749239</td>\n",
       "      <td>10.571532</td>\n",
       "      <td>14.042197</td>\n",
       "      <td>11.155579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DP01</td>\n",
       "      <td>Discovery</td>\n",
       "      <td>natural</td>\n",
       "      <td>63</td>\n",
       "      <td>9</td>\n",
       "      <td>38.714286</td>\n",
       "      <td>12.657642</td>\n",
       "      <td>10.162621</td>\n",
       "      <td>8.130034</td>\n",
       "      <td>10.349446</td>\n",
       "      <td>...</td>\n",
       "      <td>10.788551</td>\n",
       "      <td>8.972928</td>\n",
       "      <td>11.831649</td>\n",
       "      <td>6.579638</td>\n",
       "      <td>10.032035</td>\n",
       "      <td>12.329358</td>\n",
       "      <td>14.939134</td>\n",
       "      <td>10.303965</td>\n",
       "      <td>13.876263</td>\n",
       "      <td>11.085732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>DP30</td>\n",
       "      <td>Validation (Test Set 1)</td>\n",
       "      <td>natural</td>\n",
       "      <td>245</td>\n",
       "      <td>35</td>\n",
       "      <td>38.857143</td>\n",
       "      <td>12.115260</td>\n",
       "      <td>11.037353</td>\n",
       "      <td>6.541048</td>\n",
       "      <td>10.235494</td>\n",
       "      <td>...</td>\n",
       "      <td>11.053052</td>\n",
       "      <td>9.530414</td>\n",
       "      <td>12.100110</td>\n",
       "      <td>6.634040</td>\n",
       "      <td>9.352964</td>\n",
       "      <td>12.271830</td>\n",
       "      <td>14.366054</td>\n",
       "      <td>10.805234</td>\n",
       "      <td>14.887704</td>\n",
       "      <td>11.551004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>DP30</td>\n",
       "      <td>Validation (Test Set 1)</td>\n",
       "      <td>natural</td>\n",
       "      <td>252</td>\n",
       "      <td>36</td>\n",
       "      <td>38.857143</td>\n",
       "      <td>12.469027</td>\n",
       "      <td>11.543126</td>\n",
       "      <td>6.903586</td>\n",
       "      <td>10.341836</td>\n",
       "      <td>...</td>\n",
       "      <td>11.048241</td>\n",
       "      <td>9.437662</td>\n",
       "      <td>12.121246</td>\n",
       "      <td>6.724391</td>\n",
       "      <td>9.135123</td>\n",
       "      <td>11.884873</td>\n",
       "      <td>14.472117</td>\n",
       "      <td>10.867624</td>\n",
       "      <td>14.675015</td>\n",
       "      <td>10.905095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>DP30</td>\n",
       "      <td>Validation (Test Set 1)</td>\n",
       "      <td>natural</td>\n",
       "      <td>259</td>\n",
       "      <td>37</td>\n",
       "      <td>38.857143</td>\n",
       "      <td>14.027342</td>\n",
       "      <td>10.293517</td>\n",
       "      <td>7.147000</td>\n",
       "      <td>10.042527</td>\n",
       "      <td>...</td>\n",
       "      <td>10.755617</td>\n",
       "      <td>9.205752</td>\n",
       "      <td>12.077126</td>\n",
       "      <td>6.181048</td>\n",
       "      <td>9.846376</td>\n",
       "      <td>12.123202</td>\n",
       "      <td>14.680196</td>\n",
       "      <td>10.440013</td>\n",
       "      <td>14.345236</td>\n",
       "      <td>10.808394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>DP30</td>\n",
       "      <td>Validation (Test Set 1)</td>\n",
       "      <td>natural</td>\n",
       "      <td>266</td>\n",
       "      <td>38</td>\n",
       "      <td>38.857143</td>\n",
       "      <td>12.575002</td>\n",
       "      <td>10.068778</td>\n",
       "      <td>9.200918</td>\n",
       "      <td>9.555815</td>\n",
       "      <td>...</td>\n",
       "      <td>10.292866</td>\n",
       "      <td>9.692128</td>\n",
       "      <td>12.429983</td>\n",
       "      <td>6.789644</td>\n",
       "      <td>8.926737</td>\n",
       "      <td>12.228364</td>\n",
       "      <td>14.663350</td>\n",
       "      <td>10.208924</td>\n",
       "      <td>13.998535</td>\n",
       "      <td>11.138388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>DP30</td>\n",
       "      <td>Validation (Test Set 1)</td>\n",
       "      <td>natural</td>\n",
       "      <td>273</td>\n",
       "      <td>39</td>\n",
       "      <td>38.857143</td>\n",
       "      <td>13.453395</td>\n",
       "      <td>10.114277</td>\n",
       "      <td>8.743941</td>\n",
       "      <td>8.244443</td>\n",
       "      <td>...</td>\n",
       "      <td>9.950208</td>\n",
       "      <td>9.645435</td>\n",
       "      <td>12.059390</td>\n",
       "      <td>7.880887</td>\n",
       "      <td>9.496995</td>\n",
       "      <td>12.610548</td>\n",
       "      <td>14.818217</td>\n",
       "      <td>10.620437</td>\n",
       "      <td>14.579306</td>\n",
       "      <td>11.317374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>701 rows × 270 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Subject ID                   Cohort Labor onset  \\\n",
       "0         DP01                Discovery     natural   \n",
       "1         DP01                Discovery     natural   \n",
       "2         DP01                Discovery     natural   \n",
       "3         DP01                Discovery     natural   \n",
       "4         DP01                Discovery     natural   \n",
       "..         ...                      ...         ...   \n",
       "696       DP30  Validation (Test Set 1)     natural   \n",
       "697       DP30  Validation (Test Set 1)     natural   \n",
       "698       DP30  Validation (Test Set 1)     natural   \n",
       "699       DP30  Validation (Test Set 1)     natural   \n",
       "700       DP30  Validation (Test Set 1)     natural   \n",
       "\n",
       "     Gestational age (GA)/days  Gestational age (GA)/weeks  Birth GA/weeks  \\\n",
       "0                           35                           5       38.714286   \n",
       "1                           42                           6       38.714286   \n",
       "2                           49                           7       38.714286   \n",
       "3                           56                           8       38.714286   \n",
       "4                           63                           9       38.714286   \n",
       "..                         ...                         ...             ...   \n",
       "696                        245                          35       38.857143   \n",
       "697                        252                          36       38.857143   \n",
       "698                        259                          37       38.857143   \n",
       "699                        266                          38       38.857143   \n",
       "700                        273                          39       38.857143   \n",
       "\n",
       "     (+)-.alpha.-Tocopherol  (R)-2-Hydroxycaprylic acid  1,4-Dihydroxybenzene  \\\n",
       "0                 12.187246                   10.075398              9.315506   \n",
       "1                 12.643866                    9.871381              7.523938   \n",
       "2                 13.632884                   10.025761              4.431244   \n",
       "3                 12.125875                   10.253546              5.250766   \n",
       "4                 12.657642                   10.162621              8.130034   \n",
       "..                      ...                         ...                   ...   \n",
       "696               12.115260                   11.037353              6.541048   \n",
       "697               12.469027                   11.543126              6.903586   \n",
       "698               14.027342                   10.293517              7.147000   \n",
       "699               12.575002                   10.068778              9.200918   \n",
       "700               13.453395                   10.114277              8.743941   \n",
       "\n",
       "     1-Methylxanthine  ...  cis-5,8,11,14,17-Eicosapentaenoic acid  \\\n",
       "0           10.907293  ...                               11.183291   \n",
       "1           10.954945  ...                               11.018465   \n",
       "2            9.715949  ...                               10.537209   \n",
       "3            9.805404  ...                               10.672192   \n",
       "4           10.349446  ...                               10.788551   \n",
       "..                ...  ...                                     ...   \n",
       "696         10.235494  ...                               11.053052   \n",
       "697         10.341836  ...                               11.048241   \n",
       "698         10.042527  ...                               10.755617   \n",
       "699          9.555815  ...                               10.292866   \n",
       "700          8.244443  ...                                9.950208   \n",
       "\n",
       "     cis-5-Dodecenoic acid  cis-9-Palmitoleic acid  d-LIMONENE  gamma-CEHC  \\\n",
       "0                10.799411               12.059483    5.643133   10.495975   \n",
       "1                10.230143               11.844556    5.497642    9.847823   \n",
       "2                 9.326564               11.616709    6.736850    9.342694   \n",
       "3                 8.790673               11.874221    7.195789   10.022338   \n",
       "4                 8.972928               11.831649    6.579638   10.032035   \n",
       "..                     ...                     ...         ...         ...   \n",
       "696               9.530414               12.100110    6.634040    9.352964   \n",
       "697               9.437662               12.121246    6.724391    9.135123   \n",
       "698               9.205752               12.077126    6.181048    9.846376   \n",
       "699               9.692128               12.429983    6.789644    8.926737   \n",
       "700               9.645435               12.059390    7.880887    9.496995   \n",
       "\n",
       "     gamma-Glutamylleucine  ketoisocaproic acid   p-Cresol  \\\n",
       "0                12.157863            14.377687  10.635153   \n",
       "1                12.110144            14.217800  10.610887   \n",
       "2                12.174268            14.225116  10.848017   \n",
       "3                12.604769            14.749239  10.571532   \n",
       "4                12.329358            14.939134  10.303965   \n",
       "..                     ...                  ...        ...   \n",
       "696              12.271830            14.366054  10.805234   \n",
       "697              11.884873            14.472117  10.867624   \n",
       "698              12.123202            14.680196  10.440013   \n",
       "699              12.228364            14.663350  10.208924   \n",
       "700              12.610548            14.818217  10.620437   \n",
       "\n",
       "     phenylacetylglutamine  trans-Vaccenic acid  \n",
       "0                14.263246            11.150043  \n",
       "1                14.001904            10.924683  \n",
       "2                14.178476            10.705275  \n",
       "3                14.042197            11.155579  \n",
       "4                13.876263            11.085732  \n",
       "..                     ...                  ...  \n",
       "696              14.887704            11.551004  \n",
       "697              14.675015            10.905095  \n",
       "698              14.345236            10.808394  \n",
       "699              13.998535            11.138388  \n",
       "700              14.579306            11.317374  \n",
       "\n",
       "[701 rows x 270 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pregnancy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3203b4b5-fccb-40e0-a649-95df35cb1b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'koopomics.training.data_loader' from '/Users/daviddornig/Documents/Master_Thesis/Bioinf/Code/philipp-trinh/KOOPOMICS/koopomics/training/data_loader.py'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import koopomics.training.data_loader as tr\n",
    "importlib.reload(tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "313814d0-ff8f-44de-a1db-8b08aa2be1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DataLoader', 'Dataset', 'TimeSeriesDataset', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'clear_output', 'collate_fn', 'data_loader', 'dataloader_AE', 'get_dynamic_targets', 'lr_scheduler', 'nn', 'np', 'pd', 'plt', 'torch', 'train', 'train_utils', 'update_batch_loss_plot', 'update_batch_loss_subplots']\n"
     ]
    }
   ],
   "source": [
    "print(dir(tr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6d3be3a-88f3-4044-ad36-9bf01b43f89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataset\n",
    "feature_list = pregnancy_df.columns[6:]\n",
    "\n",
    "dataloader = tr.dataloader_AE(pregnancy_df, feature_list, sample_id='Subject ID', time_id='Gestational age (GA)/weeks', batch_size=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe5f3233-d83f-486b-8308-a07d1a0ba040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject ID = Sample identifier\n",
    "# feature list\n",
    "# Time identifier\n",
    "\n",
    "dfs = {subject_id: group for subject_id, group in pregnancy_df.groupby('Subject ID')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9eb88013-ab1a-48e8-8423-43fa869a1727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, df, feature_list, sample_id='Subject ID', time_id=''):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df (pd.DataFrame): The dataframe containing all the data.\n",
    "            feature_list (list): List of columns to be used as features.\n",
    "            sample_id (str): The column name representing the sample grouping (e.g., 'Subject ID').\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.feature_list = feature_list\n",
    "        self.sample_id = sample_id\n",
    "        \n",
    "        self.grouped = self.df.groupby(sample_id)\n",
    "        self.sample_ids = list(self.grouped.groups.keys()) \n",
    "        self.time_id = time_id\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Return the number of unique samples (i.e., groups based on sample_id)\n",
    "        return len(self.sample_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get the sample ID based on the index\n",
    "        current_sample_id = self.sample_ids[idx]\n",
    "        \n",
    "        # Retrieve all rows for this sample (time points) and filter by features\n",
    "        sample_df = self.grouped.get_group(current_sample_id)[self.feature_list]\n",
    "        row_indices = self.grouped.get_group(current_sample_id).index\n",
    "        time_indices = self.grouped.get_group(current_sample_id)[self.time_id].round().astype(int).values\n",
    "        \n",
    "        # Convert the filtered DataFrame (time points x features) to a tensor [num_time_points [num_features]]\n",
    "        input_data = torch.tensor(sample_df.values.astype(np.float32))  # Shape: (num_time_points, num_features)\n",
    "        \n",
    "        \n",
    "        return {\n",
    "            'input_data': input_data,  # Input data as a 2D tensor (time points, features)\n",
    "            'row_ids': row_indices.tolist(),\n",
    "            'sample_id': current_sample_id,  # The sample ID (e.g., 'Subject ID')\n",
    "            'time_ids' : time_indices.tolist()\n",
    "        }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # Collect the input_data for each sample\n",
    "    input_data = [item['input_data'] for item in batch]  # This will be a list of tensors of varying size\n",
    "    \n",
    "    # Collect the sample IDs and row indices for each sample\n",
    "    sample_ids = [item['sample_id'] for item in batch]\n",
    "    row_indices = [item['row_ids'] for item in batch]\n",
    "    time_indices = [item['time_ids'] for item in batch]\n",
    "    \n",
    "    return {\n",
    "        'input_data': input_data,  # List of 2D tensors, each with (num_time_points, num_features)\n",
    "        'sample_id': sample_ids,  # List of sample IDs\n",
    "        'row_ids': row_indices,  # List of row index lists\n",
    "        'time_ids': time_indices # List of time index lists\n",
    "    }\n",
    "\n",
    "\n",
    "# Initialize dataset\n",
    "feature_list = pregnancy_df.columns[6:]\n",
    "\n",
    "dataset = TimeSeriesDataset(pregnancy_df, feature_list, sample_id='Subject ID', time_id='Gestational age (GA)/weeks')\n",
    "\n",
    "# Create a DataLoader for batch processing\n",
    "dataloader = DataLoader(dataset, batch_size=5, shuffle=True, collate_fn=collate_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "564baf4c-d715-4708-8c0d-7a142918fad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def get_dynamic_targets(dataframe, feature_list, sample_id, sample_ids, time_id, time_ids, fwd=0, bwd=0):\n",
    "    \"\"\"\n",
    "    Get dynamic targets based on forward and backward prediction indices.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): The original DataFrame containing all data.\n",
    "        sample_id (string): The df identifier for samples (e.g. 'Subject ID').\n",
    "        sample_ids (list): List of unique sample IDs to filter the DataFrame.\n",
    "        time_id (string): The df identifier for timepoints (e.g. 'week').\n",
    "        time_ids (list): List of time indices for the target calculation.\n",
    "        fwd (int, optional): Number of forward time steps to look ahead. Should be > 0.\n",
    "        bwd (int, optional): Number of backward time steps to look back. Should be > 0.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tensors, each containing the dynamic targets for a sample.\n",
    "    \"\"\"\n",
    "\n",
    "    # Validate inputs\n",
    "    if (fwd <= 0 and bwd <= 0) or (fwd > 0 and bwd > 0):\n",
    "        raise ValueError(\"At least one of 'fwd' or 'bwd' must be specified, not both and > 0.\")\n",
    "\n",
    "    dynamic_target_rows = []\n",
    "    dynamic_target_ids = []\n",
    "    dynamic_target_time_ids = []\n",
    "    comparable_booleans = []\n",
    "\n",
    "    # Iterate over each sample ID\n",
    "    for i, sample in enumerate(sample_ids):\n",
    "        # Filter the DataFrame for the current sample\n",
    "        sample_df = dataframe[dataframe[sample_id] == sample]\n",
    "        filtered_sample_df = sample_df[feature_list]\n",
    "\n",
    "        # Initialize a list to collect target rows\n",
    "        target_rows = []\n",
    "        target_indices = []\n",
    "        comparable_targets = []\n",
    "\n",
    "        # Calculate the forward or backward indices\n",
    "        if fwd != 0:\n",
    "            target_time_idx_fwd = [time + fwd for time in time_ids[i]]\n",
    "            \n",
    "            dynamic_target_time_ids.append(target_time_idx_fwd)\n",
    "            \n",
    "            target_time_ids = target_time_idx_fwd\n",
    "\n",
    "        else:\n",
    "            target_idx_fwd = None\n",
    "        \n",
    "        if bwd != 0:\n",
    "            target_time_idx_bwd = [time - bwd for time in time_ids[i]]\n",
    "            \n",
    "            dynamic_target_time_ids.append(target_time_idx_bwd)\n",
    "            \n",
    "            target_time_ids = target_time_idx_bwd\n",
    "\n",
    "        else:\n",
    "            target_idx_bwd = None\n",
    "            \n",
    "        # Retrieve the rows for the calculated indices, or NaN if out of bounds\n",
    "        for time in target_time_ids:\n",
    "\n",
    "            if time in time_ids[i]: # Check if there exist gaps in timepoints.\n",
    "                row_id = sample_df[sample_df[time_id] == time].index[0]\n",
    "                target_rows.append(filtered_sample_df.loc[row_id].values)  # Add existing row values\n",
    "                comparable_targets.append(True)\n",
    "                target_indices.append(row_id)\n",
    "\n",
    "            else:\n",
    "                target_rows.append([np.nan] * len(filtered_sample_df.columns))  # Add NaN row values\n",
    "                comparable_targets.append(False)\n",
    "\n",
    "        # Add list of target_indices to total indices list.\n",
    "        dynamic_target_ids.append(target_indices)\n",
    "\n",
    "        # Convert target rows for the current sample into a tensor\n",
    "        target_array = np.array(target_rows)\n",
    "        dynamic_target_rows.append(torch.tensor(target_array, dtype=torch.float32))\n",
    "\n",
    "        # Add comparability booleans\n",
    "        comparable_booleans.append(comparable_targets)\n",
    "\n",
    "    return dynamic_target_rows, dynamic_target_ids, dynamic_target_time_ids, comparable_booleans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29ef7d2c-19f3-4d2c-a9af-26f1127ae527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(+)-.alpha.-Tocopherol</th>\n",
       "      <th>(R)-2-Hydroxycaprylic acid</th>\n",
       "      <th>1,4-Dihydroxybenzene</th>\n",
       "      <th>1-Methylxanthine</th>\n",
       "      <th>1-Naphthylamine</th>\n",
       "      <th>1-Oleoyl-sn-glycero-3-phosphoethanolamin...</th>\n",
       "      <th>1-Palmitoyl-2-hydroxy-sn-glycero-3-phosp...</th>\n",
       "      <th>1-Stearoyl-sn-glycero-3-phosphocholine</th>\n",
       "      <th>1-Stearoyl-sn-glycerol</th>\n",
       "      <th>1-pentadecanoyl-2-hydroxy-sn-glycero-3-p...</th>\n",
       "      <th>...</th>\n",
       "      <th>cis-5,8,11,14,17-Eicosapentaenoic acid</th>\n",
       "      <th>cis-5-Dodecenoic acid</th>\n",
       "      <th>cis-9-Palmitoleic acid</th>\n",
       "      <th>d-LIMONENE</th>\n",
       "      <th>gamma-CEHC</th>\n",
       "      <th>gamma-Glutamylleucine</th>\n",
       "      <th>ketoisocaproic acid</th>\n",
       "      <th>p-Cresol</th>\n",
       "      <th>phenylacetylglutamine</th>\n",
       "      <th>trans-Vaccenic acid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>12.425802</td>\n",
       "      <td>9.940151</td>\n",
       "      <td>9.346458</td>\n",
       "      <td>10.948009</td>\n",
       "      <td>12.238548</td>\n",
       "      <td>13.257731</td>\n",
       "      <td>12.973654</td>\n",
       "      <td>11.607291</td>\n",
       "      <td>14.632432</td>\n",
       "      <td>14.793555</td>\n",
       "      <td>...</td>\n",
       "      <td>10.890095</td>\n",
       "      <td>10.409081</td>\n",
       "      <td>12.320187</td>\n",
       "      <td>7.020098</td>\n",
       "      <td>10.516925</td>\n",
       "      <td>12.065996</td>\n",
       "      <td>15.078192</td>\n",
       "      <td>11.697351</td>\n",
       "      <td>15.374608</td>\n",
       "      <td>11.736492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>13.488137</td>\n",
       "      <td>9.854098</td>\n",
       "      <td>9.444458</td>\n",
       "      <td>10.368734</td>\n",
       "      <td>12.140843</td>\n",
       "      <td>13.950330</td>\n",
       "      <td>14.065568</td>\n",
       "      <td>11.729910</td>\n",
       "      <td>15.957605</td>\n",
       "      <td>15.858723</td>\n",
       "      <td>...</td>\n",
       "      <td>10.721470</td>\n",
       "      <td>9.898654</td>\n",
       "      <td>12.230804</td>\n",
       "      <td>5.331199</td>\n",
       "      <td>10.157811</td>\n",
       "      <td>11.956406</td>\n",
       "      <td>14.367358</td>\n",
       "      <td>11.957828</td>\n",
       "      <td>15.641462</td>\n",
       "      <td>11.514334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>13.246029</td>\n",
       "      <td>10.221606</td>\n",
       "      <td>9.384963</td>\n",
       "      <td>10.536216</td>\n",
       "      <td>12.199070</td>\n",
       "      <td>13.619825</td>\n",
       "      <td>13.807421</td>\n",
       "      <td>12.153983</td>\n",
       "      <td>15.820099</td>\n",
       "      <td>15.464307</td>\n",
       "      <td>...</td>\n",
       "      <td>10.536693</td>\n",
       "      <td>10.425716</td>\n",
       "      <td>12.393004</td>\n",
       "      <td>6.748009</td>\n",
       "      <td>10.106812</td>\n",
       "      <td>12.287791</td>\n",
       "      <td>14.306134</td>\n",
       "      <td>11.710425</td>\n",
       "      <td>15.507585</td>\n",
       "      <td>11.687867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>12.467784</td>\n",
       "      <td>10.382514</td>\n",
       "      <td>4.543732</td>\n",
       "      <td>11.208936</td>\n",
       "      <td>12.414522</td>\n",
       "      <td>13.640041</td>\n",
       "      <td>13.043924</td>\n",
       "      <td>11.787866</td>\n",
       "      <td>15.949356</td>\n",
       "      <td>15.327827</td>\n",
       "      <td>...</td>\n",
       "      <td>11.003658</td>\n",
       "      <td>10.111463</td>\n",
       "      <td>12.228382</td>\n",
       "      <td>6.140041</td>\n",
       "      <td>9.717163</td>\n",
       "      <td>12.087499</td>\n",
       "      <td>13.597653</td>\n",
       "      <td>11.825458</td>\n",
       "      <td>15.374558</td>\n",
       "      <td>11.739387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>12.489635</td>\n",
       "      <td>10.195934</td>\n",
       "      <td>8.954138</td>\n",
       "      <td>11.247966</td>\n",
       "      <td>12.753416</td>\n",
       "      <td>13.273298</td>\n",
       "      <td>13.546116</td>\n",
       "      <td>11.980306</td>\n",
       "      <td>14.804769</td>\n",
       "      <td>14.768760</td>\n",
       "      <td>...</td>\n",
       "      <td>9.971164</td>\n",
       "      <td>9.401481</td>\n",
       "      <td>12.024649</td>\n",
       "      <td>6.353860</td>\n",
       "      <td>9.969766</td>\n",
       "      <td>12.896635</td>\n",
       "      <td>15.037879</td>\n",
       "      <td>11.981087</td>\n",
       "      <td>15.762672</td>\n",
       "      <td>10.928602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>13.988499</td>\n",
       "      <td>10.082340</td>\n",
       "      <td>10.240554</td>\n",
       "      <td>11.428982</td>\n",
       "      <td>12.117136</td>\n",
       "      <td>13.747037</td>\n",
       "      <td>12.546961</td>\n",
       "      <td>11.940502</td>\n",
       "      <td>15.943817</td>\n",
       "      <td>15.667817</td>\n",
       "      <td>...</td>\n",
       "      <td>10.625949</td>\n",
       "      <td>8.844947</td>\n",
       "      <td>12.172595</td>\n",
       "      <td>5.710784</td>\n",
       "      <td>9.687481</td>\n",
       "      <td>12.042356</td>\n",
       "      <td>14.091961</td>\n",
       "      <td>11.851552</td>\n",
       "      <td>15.602911</td>\n",
       "      <td>11.437537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>13.537356</td>\n",
       "      <td>10.167389</td>\n",
       "      <td>9.441791</td>\n",
       "      <td>10.891179</td>\n",
       "      <td>12.414266</td>\n",
       "      <td>13.343521</td>\n",
       "      <td>13.545699</td>\n",
       "      <td>12.234360</td>\n",
       "      <td>14.921490</td>\n",
       "      <td>15.565114</td>\n",
       "      <td>...</td>\n",
       "      <td>10.524493</td>\n",
       "      <td>9.304888</td>\n",
       "      <td>12.037641</td>\n",
       "      <td>6.210856</td>\n",
       "      <td>9.870218</td>\n",
       "      <td>12.034437</td>\n",
       "      <td>14.208508</td>\n",
       "      <td>12.034598</td>\n",
       "      <td>15.729341</td>\n",
       "      <td>11.306020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>10.178591</td>\n",
       "      <td>10.001586</td>\n",
       "      <td>9.319354</td>\n",
       "      <td>10.960209</td>\n",
       "      <td>12.337291</td>\n",
       "      <td>12.924105</td>\n",
       "      <td>13.305955</td>\n",
       "      <td>11.776858</td>\n",
       "      <td>14.529580</td>\n",
       "      <td>14.606091</td>\n",
       "      <td>...</td>\n",
       "      <td>10.343619</td>\n",
       "      <td>8.650760</td>\n",
       "      <td>11.940205</td>\n",
       "      <td>5.775387</td>\n",
       "      <td>9.787532</td>\n",
       "      <td>12.285890</td>\n",
       "      <td>15.144465</td>\n",
       "      <td>11.824410</td>\n",
       "      <td>15.621938</td>\n",
       "      <td>10.984773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>9.922932</td>\n",
       "      <td>9.987443</td>\n",
       "      <td>8.029249</td>\n",
       "      <td>10.777103</td>\n",
       "      <td>12.311446</td>\n",
       "      <td>12.821562</td>\n",
       "      <td>13.150172</td>\n",
       "      <td>12.147272</td>\n",
       "      <td>14.698695</td>\n",
       "      <td>14.658868</td>\n",
       "      <td>...</td>\n",
       "      <td>10.640779</td>\n",
       "      <td>8.961600</td>\n",
       "      <td>12.069779</td>\n",
       "      <td>6.535149</td>\n",
       "      <td>9.749425</td>\n",
       "      <td>12.231994</td>\n",
       "      <td>14.216073</td>\n",
       "      <td>11.867467</td>\n",
       "      <td>15.653524</td>\n",
       "      <td>11.106400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>10.948244</td>\n",
       "      <td>10.120422</td>\n",
       "      <td>7.635790</td>\n",
       "      <td>11.122960</td>\n",
       "      <td>12.170785</td>\n",
       "      <td>13.027633</td>\n",
       "      <td>13.303402</td>\n",
       "      <td>12.384532</td>\n",
       "      <td>14.553590</td>\n",
       "      <td>14.725716</td>\n",
       "      <td>...</td>\n",
       "      <td>10.601510</td>\n",
       "      <td>8.683241</td>\n",
       "      <td>12.093678</td>\n",
       "      <td>6.621639</td>\n",
       "      <td>10.007895</td>\n",
       "      <td>12.185041</td>\n",
       "      <td>13.787838</td>\n",
       "      <td>12.072946</td>\n",
       "      <td>15.801390</td>\n",
       "      <td>11.137249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>12.648284</td>\n",
       "      <td>10.082579</td>\n",
       "      <td>5.591463</td>\n",
       "      <td>11.069865</td>\n",
       "      <td>11.969507</td>\n",
       "      <td>13.235915</td>\n",
       "      <td>13.545979</td>\n",
       "      <td>12.323847</td>\n",
       "      <td>15.173684</td>\n",
       "      <td>15.149847</td>\n",
       "      <td>...</td>\n",
       "      <td>10.585704</td>\n",
       "      <td>8.567937</td>\n",
       "      <td>11.953050</td>\n",
       "      <td>5.939196</td>\n",
       "      <td>9.956270</td>\n",
       "      <td>12.098249</td>\n",
       "      <td>14.083548</td>\n",
       "      <td>11.969848</td>\n",
       "      <td>15.801352</td>\n",
       "      <td>11.021689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>12.825349</td>\n",
       "      <td>10.481117</td>\n",
       "      <td>4.569970</td>\n",
       "      <td>10.515028</td>\n",
       "      <td>12.139172</td>\n",
       "      <td>12.976950</td>\n",
       "      <td>13.100658</td>\n",
       "      <td>12.126591</td>\n",
       "      <td>15.193909</td>\n",
       "      <td>14.725536</td>\n",
       "      <td>...</td>\n",
       "      <td>10.732089</td>\n",
       "      <td>9.866045</td>\n",
       "      <td>12.078110</td>\n",
       "      <td>6.267692</td>\n",
       "      <td>10.439969</td>\n",
       "      <td>12.065287</td>\n",
       "      <td>14.074192</td>\n",
       "      <td>11.915319</td>\n",
       "      <td>15.856985</td>\n",
       "      <td>11.143671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 264 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     (+)-.alpha.-Tocopherol  (R)-2-Hydroxycaprylic acid  1,4-Dihydroxybenzene  \\\n",
       "458               12.425802                    9.940151              9.346458   \n",
       "459               13.488137                    9.854098              9.444458   \n",
       "460               13.246029                   10.221606              9.384963   \n",
       "461               12.467784                   10.382514              4.543732   \n",
       "462               12.489635                   10.195934              8.954138   \n",
       "463               13.988499                   10.082340             10.240554   \n",
       "464               13.537356                   10.167389              9.441791   \n",
       "465               10.178591                   10.001586              9.319354   \n",
       "466                9.922932                    9.987443              8.029249   \n",
       "467               10.948244                   10.120422              7.635790   \n",
       "468               12.648284                   10.082579              5.591463   \n",
       "469               12.825349                   10.481117              4.569970   \n",
       "\n",
       "     1-Methylxanthine  1-Naphthylamine  \\\n",
       "458         10.948009        12.238548   \n",
       "459         10.368734        12.140843   \n",
       "460         10.536216        12.199070   \n",
       "461         11.208936        12.414522   \n",
       "462         11.247966        12.753416   \n",
       "463         11.428982        12.117136   \n",
       "464         10.891179        12.414266   \n",
       "465         10.960209        12.337291   \n",
       "466         10.777103        12.311446   \n",
       "467         11.122960        12.170785   \n",
       "468         11.069865        11.969507   \n",
       "469         10.515028        12.139172   \n",
       "\n",
       "     1-Oleoyl-sn-glycero-3-phosphoethanolamin...  \\\n",
       "458                                    13.257731   \n",
       "459                                    13.950330   \n",
       "460                                    13.619825   \n",
       "461                                    13.640041   \n",
       "462                                    13.273298   \n",
       "463                                    13.747037   \n",
       "464                                    13.343521   \n",
       "465                                    12.924105   \n",
       "466                                    12.821562   \n",
       "467                                    13.027633   \n",
       "468                                    13.235915   \n",
       "469                                    12.976950   \n",
       "\n",
       "     1-Palmitoyl-2-hydroxy-sn-glycero-3-phosp...  \\\n",
       "458                                    12.973654   \n",
       "459                                    14.065568   \n",
       "460                                    13.807421   \n",
       "461                                    13.043924   \n",
       "462                                    13.546116   \n",
       "463                                    12.546961   \n",
       "464                                    13.545699   \n",
       "465                                    13.305955   \n",
       "466                                    13.150172   \n",
       "467                                    13.303402   \n",
       "468                                    13.545979   \n",
       "469                                    13.100658   \n",
       "\n",
       "     1-Stearoyl-sn-glycero-3-phosphocholine  1-Stearoyl-sn-glycerol  \\\n",
       "458                               11.607291               14.632432   \n",
       "459                               11.729910               15.957605   \n",
       "460                               12.153983               15.820099   \n",
       "461                               11.787866               15.949356   \n",
       "462                               11.980306               14.804769   \n",
       "463                               11.940502               15.943817   \n",
       "464                               12.234360               14.921490   \n",
       "465                               11.776858               14.529580   \n",
       "466                               12.147272               14.698695   \n",
       "467                               12.384532               14.553590   \n",
       "468                               12.323847               15.173684   \n",
       "469                               12.126591               15.193909   \n",
       "\n",
       "     1-pentadecanoyl-2-hydroxy-sn-glycero-3-p...  ...  \\\n",
       "458                                    14.793555  ...   \n",
       "459                                    15.858723  ...   \n",
       "460                                    15.464307  ...   \n",
       "461                                    15.327827  ...   \n",
       "462                                    14.768760  ...   \n",
       "463                                    15.667817  ...   \n",
       "464                                    15.565114  ...   \n",
       "465                                    14.606091  ...   \n",
       "466                                    14.658868  ...   \n",
       "467                                    14.725716  ...   \n",
       "468                                    15.149847  ...   \n",
       "469                                    14.725536  ...   \n",
       "\n",
       "     cis-5,8,11,14,17-Eicosapentaenoic acid  cis-5-Dodecenoic acid  \\\n",
       "458                               10.890095              10.409081   \n",
       "459                               10.721470               9.898654   \n",
       "460                               10.536693              10.425716   \n",
       "461                               11.003658              10.111463   \n",
       "462                                9.971164               9.401481   \n",
       "463                               10.625949               8.844947   \n",
       "464                               10.524493               9.304888   \n",
       "465                               10.343619               8.650760   \n",
       "466                               10.640779               8.961600   \n",
       "467                               10.601510               8.683241   \n",
       "468                               10.585704               8.567937   \n",
       "469                               10.732089               9.866045   \n",
       "\n",
       "     cis-9-Palmitoleic acid  d-LIMONENE  gamma-CEHC  gamma-Glutamylleucine  \\\n",
       "458               12.320187    7.020098   10.516925              12.065996   \n",
       "459               12.230804    5.331199   10.157811              11.956406   \n",
       "460               12.393004    6.748009   10.106812              12.287791   \n",
       "461               12.228382    6.140041    9.717163              12.087499   \n",
       "462               12.024649    6.353860    9.969766              12.896635   \n",
       "463               12.172595    5.710784    9.687481              12.042356   \n",
       "464               12.037641    6.210856    9.870218              12.034437   \n",
       "465               11.940205    5.775387    9.787532              12.285890   \n",
       "466               12.069779    6.535149    9.749425              12.231994   \n",
       "467               12.093678    6.621639   10.007895              12.185041   \n",
       "468               11.953050    5.939196    9.956270              12.098249   \n",
       "469               12.078110    6.267692   10.439969              12.065287   \n",
       "\n",
       "     ketoisocaproic acid   p-Cresol  phenylacetylglutamine  \\\n",
       "458            15.078192  11.697351              15.374608   \n",
       "459            14.367358  11.957828              15.641462   \n",
       "460            14.306134  11.710425              15.507585   \n",
       "461            13.597653  11.825458              15.374558   \n",
       "462            15.037879  11.981087              15.762672   \n",
       "463            14.091961  11.851552              15.602911   \n",
       "464            14.208508  12.034598              15.729341   \n",
       "465            15.144465  11.824410              15.621938   \n",
       "466            14.216073  11.867467              15.653524   \n",
       "467            13.787838  12.072946              15.801390   \n",
       "468            14.083548  11.969848              15.801352   \n",
       "469            14.074192  11.915319              15.856985   \n",
       "\n",
       "     trans-Vaccenic acid  \n",
       "458            11.736492  \n",
       "459            11.514334  \n",
       "460            11.687867  \n",
       "461            11.739387  \n",
       "462            10.928602  \n",
       "463            11.437537  \n",
       "464            11.306020  \n",
       "465            10.984773  \n",
       "466            11.106400  \n",
       "467            11.137249  \n",
       "468            11.021689  \n",
       "469            11.143671  \n",
       "\n",
       "[12 rows x 264 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = pregnancy_df[pregnancy_df['Subject ID'] == 'DP21'][feature_list]\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fdb343d-4fbc-4b23-9760-a82cee2a3461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Labor onset</th>\n",
       "      <th>Gestational age (GA)/days</th>\n",
       "      <th>Gestational age (GA)/weeks</th>\n",
       "      <th>Birth GA/weeks</th>\n",
       "      <th>(+)-.alpha.-Tocopherol</th>\n",
       "      <th>(R)-2-Hydroxycaprylic acid</th>\n",
       "      <th>1,4-Dihydroxybenzene</th>\n",
       "      <th>1-Methylxanthine</th>\n",
       "      <th>...</th>\n",
       "      <th>cis-5,8,11,14,17-Eicosapentaenoic acid</th>\n",
       "      <th>cis-5-Dodecenoic acid</th>\n",
       "      <th>cis-9-Palmitoleic acid</th>\n",
       "      <th>d-LIMONENE</th>\n",
       "      <th>gamma-CEHC</th>\n",
       "      <th>gamma-Glutamylleucine</th>\n",
       "      <th>ketoisocaproic acid</th>\n",
       "      <th>p-Cresol</th>\n",
       "      <th>phenylacetylglutamine</th>\n",
       "      <th>trans-Vaccenic acid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>DP21</td>\n",
       "      <td>Discovery</td>\n",
       "      <td>natural</td>\n",
       "      <td>126</td>\n",
       "      <td>18</td>\n",
       "      <td>38.571429</td>\n",
       "      <td>12.425802</td>\n",
       "      <td>9.940151</td>\n",
       "      <td>9.346458</td>\n",
       "      <td>10.948009</td>\n",
       "      <td>...</td>\n",
       "      <td>10.890095</td>\n",
       "      <td>10.409081</td>\n",
       "      <td>12.320187</td>\n",
       "      <td>7.020098</td>\n",
       "      <td>10.516925</td>\n",
       "      <td>12.065996</td>\n",
       "      <td>15.078192</td>\n",
       "      <td>11.697351</td>\n",
       "      <td>15.374608</td>\n",
       "      <td>11.736492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>DP21</td>\n",
       "      <td>Discovery</td>\n",
       "      <td>natural</td>\n",
       "      <td>133</td>\n",
       "      <td>19</td>\n",
       "      <td>38.571429</td>\n",
       "      <td>13.488137</td>\n",
       "      <td>9.854098</td>\n",
       "      <td>9.444458</td>\n",
       "      <td>10.368734</td>\n",
       "      <td>...</td>\n",
       "      <td>10.721470</td>\n",
       "      <td>9.898654</td>\n",
       "      <td>12.230804</td>\n",
       "      <td>5.331199</td>\n",
       "      <td>10.157811</td>\n",
       "      <td>11.956406</td>\n",
       "      <td>14.367358</td>\n",
       "      <td>11.957828</td>\n",
       "      <td>15.641462</td>\n",
       "      <td>11.514334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>DP21</td>\n",
       "      <td>Discovery</td>\n",
       "      <td>natural</td>\n",
       "      <td>140</td>\n",
       "      <td>20</td>\n",
       "      <td>38.571429</td>\n",
       "      <td>13.246029</td>\n",
       "      <td>10.221606</td>\n",
       "      <td>9.384963</td>\n",
       "      <td>10.536216</td>\n",
       "      <td>...</td>\n",
       "      <td>10.536693</td>\n",
       "      <td>10.425716</td>\n",
       "      <td>12.393004</td>\n",
       "      <td>6.748009</td>\n",
       "      <td>10.106812</td>\n",
       "      <td>12.287791</td>\n",
       "      <td>14.306134</td>\n",
       "      <td>11.710425</td>\n",
       "      <td>15.507585</td>\n",
       "      <td>11.687867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>DP21</td>\n",
       "      <td>Discovery</td>\n",
       "      <td>natural</td>\n",
       "      <td>147</td>\n",
       "      <td>21</td>\n",
       "      <td>38.571429</td>\n",
       "      <td>12.467784</td>\n",
       "      <td>10.382514</td>\n",
       "      <td>4.543732</td>\n",
       "      <td>11.208936</td>\n",
       "      <td>...</td>\n",
       "      <td>11.003658</td>\n",
       "      <td>10.111463</td>\n",
       "      <td>12.228382</td>\n",
       "      <td>6.140041</td>\n",
       "      <td>9.717163</td>\n",
       "      <td>12.087499</td>\n",
       "      <td>13.597653</td>\n",
       "      <td>11.825458</td>\n",
       "      <td>15.374558</td>\n",
       "      <td>11.739387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>DP21</td>\n",
       "      <td>Discovery</td>\n",
       "      <td>natural</td>\n",
       "      <td>154</td>\n",
       "      <td>22</td>\n",
       "      <td>38.571429</td>\n",
       "      <td>12.489635</td>\n",
       "      <td>10.195934</td>\n",
       "      <td>8.954138</td>\n",
       "      <td>11.247966</td>\n",
       "      <td>...</td>\n",
       "      <td>9.971164</td>\n",
       "      <td>9.401481</td>\n",
       "      <td>12.024649</td>\n",
       "      <td>6.353860</td>\n",
       "      <td>9.969766</td>\n",
       "      <td>12.896635</td>\n",
       "      <td>15.037879</td>\n",
       "      <td>11.981087</td>\n",
       "      <td>15.762672</td>\n",
       "      <td>10.928602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>DP21</td>\n",
       "      <td>Discovery</td>\n",
       "      <td>natural</td>\n",
       "      <td>161</td>\n",
       "      <td>23</td>\n",
       "      <td>38.571429</td>\n",
       "      <td>13.988499</td>\n",
       "      <td>10.082340</td>\n",
       "      <td>10.240554</td>\n",
       "      <td>11.428982</td>\n",
       "      <td>...</td>\n",
       "      <td>10.625949</td>\n",
       "      <td>8.844947</td>\n",
       "      <td>12.172595</td>\n",
       "      <td>5.710784</td>\n",
       "      <td>9.687481</td>\n",
       "      <td>12.042356</td>\n",
       "      <td>14.091961</td>\n",
       "      <td>11.851552</td>\n",
       "      <td>15.602911</td>\n",
       "      <td>11.437537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>DP21</td>\n",
       "      <td>Discovery</td>\n",
       "      <td>natural</td>\n",
       "      <td>168</td>\n",
       "      <td>24</td>\n",
       "      <td>38.571429</td>\n",
       "      <td>13.537356</td>\n",
       "      <td>10.167389</td>\n",
       "      <td>9.441791</td>\n",
       "      <td>10.891179</td>\n",
       "      <td>...</td>\n",
       "      <td>10.524493</td>\n",
       "      <td>9.304888</td>\n",
       "      <td>12.037641</td>\n",
       "      <td>6.210856</td>\n",
       "      <td>9.870218</td>\n",
       "      <td>12.034437</td>\n",
       "      <td>14.208508</td>\n",
       "      <td>12.034598</td>\n",
       "      <td>15.729341</td>\n",
       "      <td>11.306020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>DP21</td>\n",
       "      <td>Discovery</td>\n",
       "      <td>natural</td>\n",
       "      <td>210</td>\n",
       "      <td>30</td>\n",
       "      <td>38.571429</td>\n",
       "      <td>10.178591</td>\n",
       "      <td>10.001586</td>\n",
       "      <td>9.319354</td>\n",
       "      <td>10.960209</td>\n",
       "      <td>...</td>\n",
       "      <td>10.343619</td>\n",
       "      <td>8.650760</td>\n",
       "      <td>11.940205</td>\n",
       "      <td>5.775387</td>\n",
       "      <td>9.787532</td>\n",
       "      <td>12.285890</td>\n",
       "      <td>15.144465</td>\n",
       "      <td>11.824410</td>\n",
       "      <td>15.621938</td>\n",
       "      <td>10.984773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>DP21</td>\n",
       "      <td>Discovery</td>\n",
       "      <td>natural</td>\n",
       "      <td>217</td>\n",
       "      <td>31</td>\n",
       "      <td>38.571429</td>\n",
       "      <td>9.922932</td>\n",
       "      <td>9.987443</td>\n",
       "      <td>8.029249</td>\n",
       "      <td>10.777103</td>\n",
       "      <td>...</td>\n",
       "      <td>10.640779</td>\n",
       "      <td>8.961600</td>\n",
       "      <td>12.069779</td>\n",
       "      <td>6.535149</td>\n",
       "      <td>9.749425</td>\n",
       "      <td>12.231994</td>\n",
       "      <td>14.216073</td>\n",
       "      <td>11.867467</td>\n",
       "      <td>15.653524</td>\n",
       "      <td>11.106400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>DP21</td>\n",
       "      <td>Discovery</td>\n",
       "      <td>natural</td>\n",
       "      <td>224</td>\n",
       "      <td>32</td>\n",
       "      <td>38.571429</td>\n",
       "      <td>10.948244</td>\n",
       "      <td>10.120422</td>\n",
       "      <td>7.635790</td>\n",
       "      <td>11.122960</td>\n",
       "      <td>...</td>\n",
       "      <td>10.601510</td>\n",
       "      <td>8.683241</td>\n",
       "      <td>12.093678</td>\n",
       "      <td>6.621639</td>\n",
       "      <td>10.007895</td>\n",
       "      <td>12.185041</td>\n",
       "      <td>13.787838</td>\n",
       "      <td>12.072946</td>\n",
       "      <td>15.801390</td>\n",
       "      <td>11.137249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>DP21</td>\n",
       "      <td>Discovery</td>\n",
       "      <td>natural</td>\n",
       "      <td>231</td>\n",
       "      <td>33</td>\n",
       "      <td>38.571429</td>\n",
       "      <td>12.648284</td>\n",
       "      <td>10.082579</td>\n",
       "      <td>5.591463</td>\n",
       "      <td>11.069865</td>\n",
       "      <td>...</td>\n",
       "      <td>10.585704</td>\n",
       "      <td>8.567937</td>\n",
       "      <td>11.953050</td>\n",
       "      <td>5.939196</td>\n",
       "      <td>9.956270</td>\n",
       "      <td>12.098249</td>\n",
       "      <td>14.083548</td>\n",
       "      <td>11.969848</td>\n",
       "      <td>15.801352</td>\n",
       "      <td>11.021689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>DP21</td>\n",
       "      <td>Discovery</td>\n",
       "      <td>natural</td>\n",
       "      <td>259</td>\n",
       "      <td>37</td>\n",
       "      <td>38.571429</td>\n",
       "      <td>12.825349</td>\n",
       "      <td>10.481117</td>\n",
       "      <td>4.569970</td>\n",
       "      <td>10.515028</td>\n",
       "      <td>...</td>\n",
       "      <td>10.732089</td>\n",
       "      <td>9.866045</td>\n",
       "      <td>12.078110</td>\n",
       "      <td>6.267692</td>\n",
       "      <td>10.439969</td>\n",
       "      <td>12.065287</td>\n",
       "      <td>14.074192</td>\n",
       "      <td>11.915319</td>\n",
       "      <td>15.856985</td>\n",
       "      <td>11.143671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 270 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Subject ID     Cohort Labor onset  Gestational age (GA)/days  \\\n",
       "458       DP21  Discovery     natural                        126   \n",
       "459       DP21  Discovery     natural                        133   \n",
       "460       DP21  Discovery     natural                        140   \n",
       "461       DP21  Discovery     natural                        147   \n",
       "462       DP21  Discovery     natural                        154   \n",
       "463       DP21  Discovery     natural                        161   \n",
       "464       DP21  Discovery     natural                        168   \n",
       "465       DP21  Discovery     natural                        210   \n",
       "466       DP21  Discovery     natural                        217   \n",
       "467       DP21  Discovery     natural                        224   \n",
       "468       DP21  Discovery     natural                        231   \n",
       "469       DP21  Discovery     natural                        259   \n",
       "\n",
       "     Gestational age (GA)/weeks  Birth GA/weeks  (+)-.alpha.-Tocopherol  \\\n",
       "458                          18       38.571429               12.425802   \n",
       "459                          19       38.571429               13.488137   \n",
       "460                          20       38.571429               13.246029   \n",
       "461                          21       38.571429               12.467784   \n",
       "462                          22       38.571429               12.489635   \n",
       "463                          23       38.571429               13.988499   \n",
       "464                          24       38.571429               13.537356   \n",
       "465                          30       38.571429               10.178591   \n",
       "466                          31       38.571429                9.922932   \n",
       "467                          32       38.571429               10.948244   \n",
       "468                          33       38.571429               12.648284   \n",
       "469                          37       38.571429               12.825349   \n",
       "\n",
       "     (R)-2-Hydroxycaprylic acid  1,4-Dihydroxybenzene  1-Methylxanthine  ...  \\\n",
       "458                    9.940151              9.346458         10.948009  ...   \n",
       "459                    9.854098              9.444458         10.368734  ...   \n",
       "460                   10.221606              9.384963         10.536216  ...   \n",
       "461                   10.382514              4.543732         11.208936  ...   \n",
       "462                   10.195934              8.954138         11.247966  ...   \n",
       "463                   10.082340             10.240554         11.428982  ...   \n",
       "464                   10.167389              9.441791         10.891179  ...   \n",
       "465                   10.001586              9.319354         10.960209  ...   \n",
       "466                    9.987443              8.029249         10.777103  ...   \n",
       "467                   10.120422              7.635790         11.122960  ...   \n",
       "468                   10.082579              5.591463         11.069865  ...   \n",
       "469                   10.481117              4.569970         10.515028  ...   \n",
       "\n",
       "     cis-5,8,11,14,17-Eicosapentaenoic acid  cis-5-Dodecenoic acid  \\\n",
       "458                               10.890095              10.409081   \n",
       "459                               10.721470               9.898654   \n",
       "460                               10.536693              10.425716   \n",
       "461                               11.003658              10.111463   \n",
       "462                                9.971164               9.401481   \n",
       "463                               10.625949               8.844947   \n",
       "464                               10.524493               9.304888   \n",
       "465                               10.343619               8.650760   \n",
       "466                               10.640779               8.961600   \n",
       "467                               10.601510               8.683241   \n",
       "468                               10.585704               8.567937   \n",
       "469                               10.732089               9.866045   \n",
       "\n",
       "     cis-9-Palmitoleic acid  d-LIMONENE  gamma-CEHC  gamma-Glutamylleucine  \\\n",
       "458               12.320187    7.020098   10.516925              12.065996   \n",
       "459               12.230804    5.331199   10.157811              11.956406   \n",
       "460               12.393004    6.748009   10.106812              12.287791   \n",
       "461               12.228382    6.140041    9.717163              12.087499   \n",
       "462               12.024649    6.353860    9.969766              12.896635   \n",
       "463               12.172595    5.710784    9.687481              12.042356   \n",
       "464               12.037641    6.210856    9.870218              12.034437   \n",
       "465               11.940205    5.775387    9.787532              12.285890   \n",
       "466               12.069779    6.535149    9.749425              12.231994   \n",
       "467               12.093678    6.621639   10.007895              12.185041   \n",
       "468               11.953050    5.939196    9.956270              12.098249   \n",
       "469               12.078110    6.267692   10.439969              12.065287   \n",
       "\n",
       "     ketoisocaproic acid   p-Cresol  phenylacetylglutamine  \\\n",
       "458            15.078192  11.697351              15.374608   \n",
       "459            14.367358  11.957828              15.641462   \n",
       "460            14.306134  11.710425              15.507585   \n",
       "461            13.597653  11.825458              15.374558   \n",
       "462            15.037879  11.981087              15.762672   \n",
       "463            14.091961  11.851552              15.602911   \n",
       "464            14.208508  12.034598              15.729341   \n",
       "465            15.144465  11.824410              15.621938   \n",
       "466            14.216073  11.867467              15.653524   \n",
       "467            13.787838  12.072946              15.801390   \n",
       "468            14.083548  11.969848              15.801352   \n",
       "469            14.074192  11.915319              15.856985   \n",
       "\n",
       "     trans-Vaccenic acid  \n",
       "458            11.736492  \n",
       "459            11.514334  \n",
       "460            11.687867  \n",
       "461            11.739387  \n",
       "462            10.928602  \n",
       "463            11.437537  \n",
       "464            11.306020  \n",
       "465            10.984773  \n",
       "466            11.106400  \n",
       "467            11.137249  \n",
       "468            11.021689  \n",
       "469            11.143671  \n",
       "\n",
       "[12 rows x 270 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['DP21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b8cf279-7b86-4aee-8091-b6b48422aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import koopomics.training.train_utils as trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4fa7188-10ca-4999-ac65-9eb9d5f38db4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject ID\n",
      "Gestational age (GA)/weeks\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_dynamic_targets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 33\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, sample_input \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(inputs):\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,max_step\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m     30\u001b[0m \n\u001b[1;32m     31\u001b[0m         \u001b[38;5;66;03m# ----------- Train Forward Prediction\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m         target_rows, target_indices, target_time_indices, comparable_booleans \u001b[38;5;241m=\u001b[39m \u001b[43mget_dynamic_targets\u001b[49m(pregnancy_df, feature_list, sample_id, [subject_ids[i]], time_id, [time_ids[i]], fwd\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m------------------------------fwd-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-------------------------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     36\u001b[0m         filtered_sample_inputs \u001b[38;5;241m=\u001b[39m sample_input[comparable_booleans]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_dynamic_targets' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "max_step = 1\n",
    "sample_id = 'Subject ID'\n",
    "time_id = 'Gestational age (GA)/weeks'\n",
    "\n",
    "loss_fwd = 0\n",
    "loss_bwd = 0\n",
    "loss_rev_cons = 0\n",
    "loss_tem_cons = 0\n",
    "total_loss = 0\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for i, batch in enumerate(dataloader):\n",
    "    inputs = batch['input_data']  \n",
    "    subject_ids = batch['sample_id'] \n",
    "    row_idxs = batch['row_ids']\n",
    "    time_ids = batch['time_ids']\n",
    "    \n",
    "    sample_dfs = batch['sample_df']\n",
    "    feature_list = batch['feature_list']\n",
    "    sample_id = batch['sample_id']\n",
    "    time_id = batch['time_id']\n",
    "    \n",
    "    for i, sample_input in enumerate(inputs):\n",
    "\n",
    "\n",
    "        for step in list(range(1,max_step+1,1)):\n",
    "    \n",
    "            # ----------- Train Forward Prediction\n",
    "\n",
    "            target_rows, target_indices, target_time_indices, comparable_booleans = trf.get_dynamic_targets(sample_df[i], feature_list, time_id,\n",
    "                                                                                                            [time_ids[i]], fwd=20)\n",
    "            print(f'------------------------------fwd-{step}-------------------------------------------------')\n",
    "\n",
    "            filtered_sample_inputs = sample_input[comparable_booleans]\n",
    "            \n",
    "            if len(filtered_sample_inputs) > 0:\n",
    "                print('..........................................')\n",
    "                print(subject_ids[i])\n",
    "                print('..........................................')\n",
    "                print(filtered_sample_inputs)\n",
    "                \n",
    "                print('..........................................')\n",
    "                sample_output = [tensor.clone() for tensor in filtered_sample_inputs]\n",
    "                print('..........................................')\n",
    "                target = target_rows[0][comparable_booleans]\n",
    "                print(target_rows[0][comparable_booleans])\n",
    "                print('..........................................')\n",
    "                print('..........................................')\n",
    "                bwd_o, fwd_o = LinKoopAE_model.predict(filtered_sample_inputs, fwd=20)\n",
    "                print(fwd_o[0])\n",
    "                print(criterion(fwd_o[0], target))\n",
    "                print('..........................................')\n",
    "                print('..........................................')\n",
    "\n",
    "            else: \n",
    "                break\n",
    "                \n",
    "        for step in list(range(1,max_step+1,1)):\n",
    "            # ----------- Train Backward Prediction\n",
    "            target_rows, target_indices, target_time_indices, comparable_booleans = get_dynamic_targets(pregnancy_df, feature_list, sample_id, [subject_ids[i]], time_id, [time_ids[i]], bwd=step)\n",
    "\n",
    "            print(f'------------------------------bwd-{step}-------------------------------------------------')\n",
    "\n",
    "\n",
    "            filtered_sample_inputs = sample_input[comparable_booleans]\n",
    "\n",
    "            if len(filtered_sample_inputs) > 0:\n",
    "            \n",
    "                print(filtered_sample_inputs)\n",
    "                print('..........................................')\n",
    "                sample_output = [tensor.clone() for tensor in filtered_sample_inputs]\n",
    "                print('..........................................')\n",
    "                print(target_rows[0][comparable_booleans])\n",
    "                print('..........................................')\n",
    "\n",
    "            else: \n",
    "                break\n",
    "\n",
    "             \n",
    "            \n",
    "    \n",
    "\n",
    "    if i == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50ab8e72-3a81-44e9-9a95-9cfaf75e004a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def update_batch_loss_plot(epoch, fwd_loss_batch_values, bwd_loss_batch_values, inv_cons_loss_batch_values, temp_cons_loss_batch_values, total_loss_batch_values):\n",
    "    # Clear the output to update the plot\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # Create a single figure\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Plot Fwd Loss\n",
    "    plt.plot(range(epoch + 1), fwd_loss_batch_values, label='Fwd Loss', marker='o', color='blue')\n",
    "\n",
    "    # Plot Bwd Loss\n",
    "    plt.plot(range(epoch + 1), bwd_loss_batch_values, label='Bwd Loss', marker='o', color='orange')\n",
    "\n",
    "    # Plot Inv Cons Loss\n",
    "    plt.plot(range(epoch + 1), inv_cons_loss_batch_values, label='Inv Cons Loss', marker='o', color='green')\n",
    "\n",
    "    # Plot Temp Cons Loss\n",
    "    plt.plot(range(epoch + 1), temp_cons_loss_batch_values, label='Temp Cons Loss', marker='o', color='red')\n",
    "\n",
    "    # Plot Total Loss\n",
    "    plt.plot(range(epoch + 1), total_loss_batch_values, label='Total Loss', color='purple', marker='o',)\n",
    "\n",
    "    # Adding titles and labels\n",
    "    plt.title('Loss Values per Batch')\n",
    "    plt.xlabel('Batch Number')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "    # Adjust layout and show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.pause(0)\n",
    "\n",
    "\n",
    "def update_batch_loss_subplots(epoch_list, batch_list, \n",
    "                               fwd_loss_batch_values, bwd_loss_batch_values, \n",
    "                               inv_cons_loss_batch_values, temp_cons_loss_batch_values, \n",
    "                               total_loss_batch_values, epoch_total_loss, model_name='Koop'):\n",
    "    # Clear the output to update the plot\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axs = plt.subplots(3, 2, figsize=(12, 8))\n",
    "    \n",
    "    # Flatten the array of axes for easy iteration\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    # Plot Training Errors\n",
    "    axs[0].plot(batch_list, fwd_loss_batch_values, label='Fwd Loss', marker='o', color='blue')\n",
    "    axs[0].set_title('Fwd Loss per Batch')\n",
    "    axs[0].set_xlabel('Batch_Nr')\n",
    "    axs[0].set_ylabel('Log Loss')\n",
    "    axs[0].set_yscale('log')\n",
    "    axs[0].grid()\n",
    "    axs[0].legend()\n",
    "\n",
    "    # Plot Validation Errors\n",
    "    axs[1].plot(batch_list, bwd_loss_batch_values, label='Bwd Loss', marker='o', color='orange')\n",
    "    axs[1].set_title('Bwd Loss per Batch')\n",
    "    axs[1].set_xlabel('Batch_Nr')\n",
    "    axs[1].set_ylabel('Log Loss')\n",
    "    axs[1].set_yscale('log')\n",
    "    axs[1].grid()\n",
    "    axs[1].legend()\n",
    "\n",
    "    axs[2].plot(batch_list, inv_cons_loss_batch_values, label='Inv Cons Loss', marker='o', color='cyan')\n",
    "    axs[2].set_title('Inv Cons Loss per Batch')\n",
    "    axs[2].set_xlabel('Batch_Nr')\n",
    "    axs[2].set_ylabel('Log Loss')\n",
    "    axs[2].set_yscale('log')\n",
    "    axs[2].grid()\n",
    "    axs[2].legend()\n",
    "\n",
    "    axs[3].plot(batch_list, temp_cons_loss_batch_values, label='Temp Cons Loss', marker='o', color='green')\n",
    "    axs[3].set_title('Temp Cons Loss per Batch')\n",
    "    axs[3].set_xlabel('Batch_Nr')\n",
    "    axs[3].set_ylabel('Log Loss')\n",
    "    axs[3].set_yscale('log')\n",
    "    axs[3].grid()\n",
    "    axs[3].legend()\n",
    "\n",
    "    axs[4].plot(batch_list, total_loss_batch_values, label='Total Loss', marker='o', color='purple')\n",
    "    axs[4].set_title('Total Loss per Batch')\n",
    "    axs[4].set_xlabel('Batch_Nr')\n",
    "    axs[4].set_ylabel('Log Loss')\n",
    "    axs[4].set_yscale('log')\n",
    "    axs[4].grid()\n",
    "\n",
    "    axs[5].plot(epoch_list, epoch_total_loss, label='Avg Total Loss', marker='o', color='purple')\n",
    "    axs[5].set_title('Avg Total Loss per Epoch')\n",
    "    axs[5].set_xlabel('Epoch')\n",
    "    axs[5].set_ylabel('Log Loss')\n",
    "    axs[5].set_yscale('log')\n",
    "    axs[5].grid()\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.draw()\n",
    "\n",
    "\n",
    "    plt.savefig(f'{model_name}-training_batch_loss_subplots.png', dpi=300)\n",
    "\n",
    "    # Save the data to a NumPy file\n",
    "    np.savez(f'{model_name}-training_batch_loss_data.npz', \n",
    "             batch=batch_list,\n",
    "             epoch=epoch_list,\n",
    "             fwd_loss=fwd_loss_batch_values,\n",
    "             bwd_loss=bwd_loss_batch_values,\n",
    "             inv_cons_loss=inv_cons_loss_batch_values,\n",
    "             temp_cons_loss=temp_cons_loss_batch_values,\n",
    "             total_loss=total_loss_batch_values,\n",
    "             avg_total_loss=epoch_total_loss)\n",
    "    \n",
    "    \n",
    "    plt.pause(0.1)\n",
    "\n",
    "\n",
    "def lr_scheduler(optimizer, epoch, lr_decay_rate=0.8, decayEpochs=[]):\n",
    "        \"\"\"Decay learning rate by a factor of lr_decay_rate every lr_decay_epoch epochs\"\"\"\n",
    "        if epoch in decayEpochs:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] *= lr_decay_rate\n",
    "            return optimizer\n",
    "        else:\n",
    "            return optimizer\n",
    "\n",
    "# Example training loop with the Identity model\n",
    "def train(model, dataloader, lr, learning_rate_change, decayEpochs=[40, 80, 120, 160], num_epochs=10,  max_Kstep=2, weight_decay=0.01, model_name='Koop'):\n",
    "    model.train()\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    \n",
    "\n",
    "             \n",
    "    \n",
    "    epoch_list = []\n",
    "    batch_list = []\n",
    "    total_loss_epoch = []\n",
    "    fwd_loss_batch_values = []\n",
    "    bwd_loss_batch_values = []\n",
    "    inv_cons_loss_batch_values = []\n",
    "    temp_cons_loss_batch_values = []\n",
    "    total_loss_batch_values = []\n",
    "    batches = 1\n",
    "    for epoch in range(num_epochs+1):\n",
    "        print(f'----------Training epoch--------')\n",
    "        print(f'----------------{epoch}---------------')\n",
    "        print('')\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for i, batch in enumerate(dataloader):\n",
    "            inputs = batch['input_data']  \n",
    "            subject_ids = batch['sample_id'] \n",
    "            row_idxs = batch['row_ids']\n",
    "            time_ids = batch['time_ids']\n",
    "            \n",
    "            loss_fwd_total = 0\n",
    "            loss_bwd_total = 0\n",
    "            \n",
    "            loss_inv_cons_total = 0\n",
    "            \n",
    "            loss_temp_cons_total = 0\n",
    "            \n",
    "            # Loop over each sample in the batch\n",
    "            for i, sample_input in enumerate(inputs):\n",
    "\n",
    "                \n",
    "                # ------------------- Forward prediction ------------------\n",
    "    \n",
    "                for step in range(1, max_Kstep+1):\n",
    "                    \n",
    "                    # Get dynamic forward targets\n",
    "                    target_rows, target_indices, target_time_indices, comparable_booleans = get_dynamic_targets(\n",
    "                        pregnancy_df, feature_list, sample_id, [subject_ids[i]], time_id, [time_ids[i]], fwd=step\n",
    "                    )\n",
    "                    \n",
    "                    filtered_sample_inputs = sample_input[comparable_booleans]\n",
    "                    \n",
    "                    if len(filtered_sample_inputs) > 0:\n",
    "                        bwd_output, fwd_output = model(filtered_sample_inputs, fwd=step) \n",
    "                        \n",
    "\n",
    "                        target = target_rows[0][comparable_booleans]\n",
    "                        \n",
    "                        # Compute loss\n",
    "                        loss_fwd = criterion(fwd_output[-1], target)\n",
    "                        loss_fwd_total += loss_fwd\n",
    "                        \n",
    "                        if step > 1: # Calculate fwd temporary consistency loss\n",
    "                            target_id_tensor = torch.tensor(target_indices)\n",
    "                            past_mask = torch.isin(past_fwd_prediction_ids, target_id_tensor)\n",
    "                            current_mask = torch.isin(target_id_tensor, past_fwd_prediction_ids)\n",
    "                            # Check the shape of past_mask before squeezing\n",
    "                            if past_mask.dim() > 1:  # Only squeeze if it's more than 1D\n",
    "                                past_mask = past_mask.squeeze(0)\n",
    "                            \n",
    "                            # Check the shape of current_mask before squeezing\n",
    "                            if current_mask.dim() > 1:  # Only squeeze if it's more than 1D\n",
    "                                current_mask = current_mask.squeeze(0)\n",
    "\n",
    "                            loss_fwd_temp_cons = criterion(fwd_output[-1][current_mask], past_fwd_prediction[past_mask])\n",
    "                            loss_temp_cons_total += loss_fwd_temp_cons\n",
    "                        \n",
    "                        past_fwd_prediction = fwd_output[-1]\n",
    "                        past_fwd_prediction_ids = torch.tensor(target_indices)\n",
    "                    else:\n",
    "                        break\n",
    "    \n",
    "                        \n",
    "                # ------------------- Backward prediction ------------------\n",
    "                for step in range(1, max_Kstep+1):\n",
    "                    \n",
    "                    # Get dynamic forward targets\n",
    "                    target_rows, target_indices, target_time_indices, comparable_booleans = get_dynamic_targets(\n",
    "                        pregnancy_df, feature_list, sample_id, [subject_ids[i]], time_id, [time_ids[i]], bwd=step\n",
    "                    )\n",
    "                    \n",
    "                    filtered_sample_inputs = sample_input[comparable_booleans]\n",
    "                    \n",
    "                    if len(filtered_sample_inputs) > 0:\n",
    "                        bwd_output, fwd_output = model(filtered_sample_inputs, bwd=step)  # Model returns input\n",
    "                        target = target_rows[0][comparable_booleans]\n",
    "                        \n",
    "                        # Compute loss\n",
    "                        loss_bwd = criterion(bwd_output[-1], target)\n",
    "                        loss_bwd_total += loss_bwd\n",
    "    \n",
    "                        \n",
    "                        if step > 1: # Calculate bwd temporary consistency loss\n",
    "                            target_id_tensor = torch.tensor(target_indices)\n",
    "                            past_mask = torch.isin(past_bwd_prediction_ids, target_id_tensor)\n",
    "                            current_mask = torch.isin(target_id_tensor, past_bwd_prediction_ids)\n",
    "                            # Check the shape of past_mask before squeezing\n",
    "                            if past_mask.dim() > 1:  # Only squeeze if it's more than 1D\n",
    "                                past_mask = past_mask.squeeze(0)\n",
    "                            \n",
    "                            # Check the shape of current_mask before squeezing\n",
    "                            if current_mask.dim() > 1:  # Only squeeze if it's more than 1D\n",
    "                                current_mask = current_mask.squeeze(0)\n",
    "                            \n",
    "                            loss_bwd_temp_cons = criterion(bwd_output[-1][current_mask], past_bwd_prediction[past_mask])\n",
    "                            loss_temp_cons_total += loss_bwd_temp_cons\n",
    "    \n",
    "                        past_bwd_prediction = bwd_output[-1]\n",
    "                        past_bwd_prediction_ids = torch.tensor(target_indices)\n",
    "                    else:\n",
    "                        break\n",
    "                        \n",
    "                # ------------------- Inverse Consistency Calculation ------------------\n",
    "                    B, F = model.Kmatrix()\n",
    "\n",
    "                    K = F.shape[-1]\n",
    "    \n",
    "                    for k in range(1,K+1):\n",
    "                        Fs1 = F[:,:k]\n",
    "                        Bs1 = B[:k,:]\n",
    "                        Fs2 = F[:k,:]\n",
    "                        Bs2 = B[:,:k]\n",
    "    \n",
    "                        Ik = torch.eye(k).float()#.to(device)\n",
    "    \n",
    "                        loss_inv_cons = (torch.sum((torch.matmul(Bs1, Fs1) - Ik)**2) + \\\n",
    "                                             torch.sum((torch.matmul(Fs2, Bs2) - Ik)**2) ) / (2.0*k)\n",
    "                        loss_inv_cons_total += loss_inv_cons\n",
    "    \n",
    "\n",
    "            # ------------------ TOTAL Batch Loss Calculation ---------------------\n",
    "            loss_fwd_total_avg = loss_fwd_total/len(inputs)\n",
    "            loss_bwd_total_avg = loss_bwd_total/len(inputs)\n",
    "            \n",
    "            loss_inv_cons_total_avg = loss_inv_cons_total/len(inputs)\n",
    "            \n",
    "            loss_temp_cons_total_avg = loss_temp_cons_total/len(inputs)\n",
    "        \n",
    "            loss_total = loss_fwd_total_avg + loss_bwd_total_avg + loss_inv_cons_total_avg + loss_temp_cons_total_avg\n",
    "\n",
    "            # Noting down Batch Losses:\n",
    "            fwd_loss_batch_values.append(loss_fwd_total_avg.detach().numpy())\n",
    "            bwd_loss_batch_values.append(loss_bwd_total_avg.detach().numpy())\n",
    "            inv_cons_loss_batch_values.append(loss_inv_cons_total_avg.detach().numpy())\n",
    "            temp_cons_loss_batch_values.append(loss_temp_cons_total_avg.detach().numpy())\n",
    "            total_loss_batch_values.append(loss_total.detach().numpy())\n",
    "            batch_list.append(batches)\n",
    "\n",
    "            # Cell Output Info:\n",
    "            print(f'Batch Nr. {batches}')\n",
    "            print(f'Total Loss: {loss_total}')\n",
    "            print(f'FwdLoss: {loss_fwd_total_avg}')\n",
    "            print(f'BwdLoss: {loss_bwd_total_avg}')\n",
    "            print(f'Inv_Cons_Loss: {loss_inv_cons_total_avg}')\n",
    "            print(f'Temp_Cons_Loss: {loss_temp_cons_total_avg}')\n",
    "            batches += 1\n",
    "            \n",
    "            \n",
    "            # ================ Backward Propagation =================================\n",
    "            optimizer.zero_grad()\n",
    "            loss_total.backward()\n",
    "            #torch.nn.utils.clip_grad_norm_(model.parameters(), gradclip) # gradient clip\n",
    "            optimizer.step()\n",
    "\n",
    "        # Noting down epoch info and adjusting cell output:\n",
    "        total_loss_epoch.append(np.mean(total_loss_batch_values))\n",
    "        epoch_list.append(epoch+1)\n",
    "        \n",
    "        if epoch in list(range(0,200,10)):\n",
    "            clear_output(wait=True)\n",
    "            update_batch_loss_subplots(epoch_list, batch_list, fwd_loss_batch_values,\n",
    "                            bwd_loss_batch_values, inv_cons_loss_batch_values,\n",
    "                            temp_cons_loss_batch_values, total_loss_batch_values,\n",
    "                            total_loss_epoch, model_name=model_name)\n",
    "        \n",
    "        # schedule learning rate decay    \n",
    "        optimizer = lr_scheduler(optimizer, epoch, lr_decay_rate=learning_rate_change, decayEpochs=decayEpochs)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "daa57fff-c8df-4f8f-8569-2bd709f9ba77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KoopmanModel(\n",
       "  (embedding): FF_AE(\n",
       "    (encode): Sequential(\n",
       "      (0): Linear(in_features=264, out_features=100, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=100, out_features=20, bias=True)\n",
       "    )\n",
       "    (decode): Sequential(\n",
       "      (0): Linear(in_features=20, out_features=100, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=100, out_features=264, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (operator): LinearizingKoop(\n",
       "    (linearizer): FFLinearizer(\n",
       "      (lin_encode): Sequential(\n",
       "        (0): Linear(in_features=20, out_features=30, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=30, out_features=50, bias=True)\n",
       "      )\n",
       "      (lin_decode): Sequential(\n",
       "        (0): Linear(in_features=50, out_features=30, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=30, out_features=20, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (koop): InvKoop()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinKoopAE_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b27abece-509d-4848-88c6-c2b78e4a0597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_', 'LinKoopAE_model', '_10', '_23']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_variable_name = [name for name, value in locals().items() if value is LinKoopAE_model]\n",
    "model_variable_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eae805-35ec-4db6-8c4e-f983dc8f46fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e4ad8fe-b720-4430-801f-fc591c87f3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1161, 0.7452, 0.3490,  ..., 0.6056, 0.5977, 0.8785],\n",
      "        [0.8543, 0.2326, 0.9487,  ..., 0.2159, 0.8622, 0.4500],\n",
      "        [0.3783, 0.0019, 0.6409,  ..., 0.8978, 0.6373, 0.7323],\n",
      "        ...,\n",
      "        [0.1883, 0.6439, 0.1534,  ..., 0.4870, 0.7121, 0.1587],\n",
      "        [0.4447, 0.4113, 0.0212,  ..., 0.3024, 0.4913, 0.9982],\n",
      "        [0.2178, 0.7835, 0.4784,  ..., 0.0926, 0.2211, 0.7958]])\n"
     ]
    }
   ],
   "source": [
    "bwdm, fwdm = LinKoopAE_model.Kmatrix()\n",
    "print(fwdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da178666-ad7e-4f1b-816a-ba82eb3716e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([],\n",
       " [tensor([[-0.0623, -0.0619,  0.0426,  ..., -0.0189, -0.1134,  0.0417],\n",
       "          [-0.0611, -0.0618,  0.0424,  ..., -0.0203, -0.1131,  0.0420],\n",
       "          [-0.0611, -0.0616,  0.0418,  ..., -0.0204, -0.1133,  0.0418],\n",
       "          ...,\n",
       "          [-0.0597, -0.0612,  0.0419,  ..., -0.0198, -0.1133,  0.0415],\n",
       "          [-0.0617, -0.0621,  0.0422,  ..., -0.0185, -0.1134,  0.0413],\n",
       "          [-0.0623, -0.0620,  0.0419,  ..., -0.0212, -0.1130,  0.0425]],\n",
       "         grad_fn=<AddmmBackward0>)])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinKoopAE_model.predict(filtered_sample_inputs, fwd=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e2e2c79-03ff-4871-9b5f-333f5717aee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[True, False, True]])\n",
    "a.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19d9ef78-3641-42e9-9da3-4b1fe2d39dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False,  True])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a154a3f9-f309-4ab2-b141-855a6e14db35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Training epoch--------\n",
      "----------------41---------------\n",
      "\n",
      "---------------Batch Nr. 247-------------------\n",
      "Total Loss: 1017427.0\n",
      "FwdLoss: 8.110095977783203\n",
      "BwdLoss: 8.096681594848633\n",
      "Inv_Cons_Loss: 1017410.8125\n",
      "Temp_Cons_Loss: 0.007170423865318298\n",
      "---------------Batch Nr. 248-------------------\n",
      "Total Loss: 1017101.1875\n",
      "FwdLoss: 7.3505730628967285\n",
      "BwdLoss: 7.312294006347656\n",
      "Inv_Cons_Loss: 1017086.5\n",
      "Temp_Cons_Loss: 0.008018371649086475\n",
      "---------------Batch Nr. 249-------------------\n",
      "Total Loss: 1016774.25\n",
      "FwdLoss: 7.318927764892578\n",
      "BwdLoss: 7.307387351989746\n",
      "Inv_Cons_Loss: 1016759.625\n",
      "Temp_Cons_Loss: 0.0044116368517279625\n",
      "---------------Batch Nr. 250-------------------\n",
      "Total Loss: 1016445.5625\n",
      "FwdLoss: 7.480368614196777\n",
      "BwdLoss: 7.439763069152832\n",
      "Inv_Cons_Loss: 1016430.625\n",
      "Temp_Cons_Loss: 0.0045719570480287075\n",
      "---------------Batch Nr. 251-------------------\n",
      "Total Loss: 894184.5\n",
      "FwdLoss: 6.865988731384277\n",
      "BwdLoss: 6.83834981918335\n",
      "Inv_Cons_Loss: 894170.8125\n",
      "Temp_Cons_Loss: 0.007537248078733683\n",
      "---------------Batch Nr. 252-------------------\n",
      "Total Loss: 1015792.875\n",
      "FwdLoss: 7.621316432952881\n",
      "BwdLoss: 7.55212926864624\n",
      "Inv_Cons_Loss: 1015777.6875\n",
      "Temp_Cons_Loss: 0.007753006182610989\n",
      "----------Training epoch--------\n",
      "----------------42---------------\n",
      "\n",
      "---------------Batch Nr. 253-------------------\n",
      "Total Loss: 1015468.1875\n",
      "FwdLoss: 7.440051078796387\n",
      "BwdLoss: 7.433393955230713\n",
      "Inv_Cons_Loss: 1015453.3125\n",
      "Temp_Cons_Loss: 0.0038644156884402037\n",
      "---------------Batch Nr. 254-------------------\n",
      "Total Loss: 1015144.3125\n",
      "FwdLoss: 7.7437028884887695\n",
      "BwdLoss: 7.74722146987915\n",
      "Inv_Cons_Loss: 1015128.8125\n",
      "Temp_Cons_Loss: 0.003224095795303583\n",
      "---------------Batch Nr. 255-------------------\n",
      "Total Loss: 1014816.1875\n",
      "FwdLoss: 7.67236328125\n",
      "BwdLoss: 7.654749870300293\n",
      "Inv_Cons_Loss: 1014800.875\n",
      "Temp_Cons_Loss: 0.006235391832888126\n",
      "---------------Batch Nr. 256-------------------\n",
      "Total Loss: 892748.75\n",
      "FwdLoss: 6.229438781738281\n",
      "BwdLoss: 6.2100348472595215\n",
      "Inv_Cons_Loss: 892736.3125\n",
      "Temp_Cons_Loss: 0.007522457744926214\n",
      "---------------Batch Nr. 257-------------------\n",
      "Total Loss: 1014158.1875\n",
      "FwdLoss: 7.282469749450684\n",
      "BwdLoss: 7.271460056304932\n",
      "Inv_Cons_Loss: 1014143.625\n",
      "Temp_Cons_Loss: 0.004745649639517069\n",
      "---------------Batch Nr. 258-------------------\n",
      "Total Loss: 1013840.0625\n",
      "FwdLoss: 8.218233108520508\n",
      "BwdLoss: 8.211418151855469\n",
      "Inv_Cons_Loss: 1013823.625\n",
      "Temp_Cons_Loss: 0.0030213226564228535\n",
      "----------Training epoch--------\n",
      "----------------43---------------\n",
      "\n",
      "---------------Batch Nr. 259-------------------\n",
      "Total Loss: 1013506.375\n",
      "FwdLoss: 6.775365352630615\n",
      "BwdLoss: 6.762415409088135\n",
      "Inv_Cons_Loss: 1013492.8125\n",
      "Temp_Cons_Loss: 0.004074383527040482\n",
      "---------------Batch Nr. 260-------------------\n",
      "Total Loss: 1013181.0\n",
      "FwdLoss: 7.659482479095459\n",
      "BwdLoss: 7.640039920806885\n",
      "Inv_Cons_Loss: 1013165.6875\n",
      "Temp_Cons_Loss: 0.005089781247079372\n",
      "---------------Batch Nr. 261-------------------\n",
      "Total Loss: 1012853.625\n",
      "FwdLoss: 7.1653642654418945\n",
      "BwdLoss: 7.161661624908447\n",
      "Inv_Cons_Loss: 1012839.3125\n",
      "Temp_Cons_Loss: 0.004552786238491535\n",
      "---------------Batch Nr. 262-------------------\n",
      "Total Loss: 891027.5625\n",
      "FwdLoss: 6.606665134429932\n",
      "BwdLoss: 6.61434268951416\n",
      "Inv_Cons_Loss: 891014.3125\n",
      "Temp_Cons_Loss: 0.003562274156138301\n",
      "---------------Batch Nr. 263-------------------\n",
      "Total Loss: 1012210.125\n",
      "FwdLoss: 8.674878120422363\n",
      "BwdLoss: 8.666495323181152\n",
      "Inv_Cons_Loss: 1012192.8125\n",
      "Temp_Cons_Loss: 0.0031555802561342716\n",
      "---------------Batch Nr. 264-------------------\n",
      "Total Loss: 1011887.875\n",
      "FwdLoss: 7.6175642013549805\n",
      "BwdLoss: 7.613333702087402\n",
      "Inv_Cons_Loss: 1011872.625\n",
      "Temp_Cons_Loss: 0.00410697003826499\n",
      "----------Training epoch--------\n",
      "----------------44---------------\n",
      "\n",
      "---------------Batch Nr. 265-------------------\n",
      "Total Loss: 890171.625\n",
      "FwdLoss: 6.40829610824585\n",
      "BwdLoss: 6.3931732177734375\n",
      "Inv_Cons_Loss: 890158.8125\n",
      "Temp_Cons_Loss: 0.006059377454221249\n",
      "---------------Batch Nr. 266-------------------\n",
      "Total Loss: 1011234.4375\n",
      "FwdLoss: 8.902853012084961\n",
      "BwdLoss: 8.890645980834961\n",
      "Inv_Cons_Loss: 1011216.625\n",
      "Temp_Cons_Loss: 0.005659659393131733\n",
      "---------------Batch Nr. 267-------------------\n",
      "Total Loss: 1010907.9375\n",
      "FwdLoss: 7.671368598937988\n",
      "BwdLoss: 7.662545680999756\n",
      "Inv_Cons_Loss: 1010892.625\n",
      "Temp_Cons_Loss: 0.00375602999702096\n",
      "---------------Batch Nr. 268-------------------\n",
      "Total Loss: 1010579.0\n",
      "FwdLoss: 7.061472415924072\n",
      "BwdLoss: 7.060377597808838\n",
      "Inv_Cons_Loss: 1010564.875\n",
      "Temp_Cons_Loss: 0.003509923815727234\n",
      "---------------Batch Nr. 269-------------------\n",
      "Total Loss: 1010251.0\n",
      "FwdLoss: 7.0609636306762695\n",
      "BwdLoss: 7.045191287994385\n",
      "Inv_Cons_Loss: 1010236.875\n",
      "Temp_Cons_Loss: 0.005500413477420807\n",
      "---------------Batch Nr. 270-------------------\n",
      "Total Loss: 1009935.125\n",
      "FwdLoss: 7.684500694274902\n",
      "BwdLoss: 7.64658260345459\n",
      "Inv_Cons_Loss: 1009919.8125\n",
      "Temp_Cons_Loss: 0.006135150790214539\n",
      "----------Training epoch--------\n",
      "----------------45---------------\n",
      "\n",
      "---------------Batch Nr. 271-------------------\n",
      "Total Loss: 1009609.6875\n",
      "FwdLoss: 7.941988468170166\n",
      "BwdLoss: 7.921358585357666\n",
      "Inv_Cons_Loss: 1009593.8125\n",
      "Temp_Cons_Loss: 0.004021113738417625\n",
      "---------------Batch Nr. 272-------------------\n",
      "Total Loss: 1009285.9375\n",
      "FwdLoss: 6.820609092712402\n",
      "BwdLoss: 6.822727203369141\n",
      "Inv_Cons_Loss: 1009272.3125\n",
      "Temp_Cons_Loss: 0.0030096988193690777\n",
      "---------------Batch Nr. 273-------------------\n",
      "Total Loss: 1008962.9375\n",
      "FwdLoss: 7.33605432510376\n",
      "BwdLoss: 7.319044589996338\n",
      "Inv_Cons_Loss: 1008948.3125\n",
      "Temp_Cons_Loss: 0.0048210835084319115\n",
      "---------------Batch Nr. 274-------------------\n",
      "Total Loss: 1008641.1875\n",
      "FwdLoss: 7.931458950042725\n",
      "BwdLoss: 7.916440486907959\n",
      "Inv_Cons_Loss: 1008625.3125\n",
      "Temp_Cons_Loss: 0.004619423300027847\n",
      "---------------Batch Nr. 275-------------------\n",
      "Total Loss: 1008312.6875\n",
      "FwdLoss: 8.091333389282227\n",
      "BwdLoss: 8.094754219055176\n",
      "Inv_Cons_Loss: 1008296.5\n",
      "Temp_Cons_Loss: 0.0030014982912689447\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m dyntargetinfo\u001b[38;5;241m=\u001b[39m[pregnancy_df, feature_list, sample_id, time_id]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Run training loop\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mtr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLinKoopAE_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate_change\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_Kstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTestingKoop\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdyntargetinfo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdyntargetinfo\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Master_Thesis/Bioinf/Code/philipp-trinh/KOOPOMICS/koopomics/training/train_utils.py:327\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, lr, learning_rate_change, decayEpochs, num_epochs, max_Kstep, weight_decay, model_name, dyntargetinfo)\u001b[0m\n\u001b[1;32m    324\u001b[0m filtered_sample_inputs \u001b[38;5;241m=\u001b[39m sample_input[comparable_booleans]\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(filtered_sample_inputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 327\u001b[0m     bwd_output, fwd_output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_sample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Model returns input\u001b[39;00m\n\u001b[1;32m    328\u001b[0m     target \u001b[38;5;241m=\u001b[39m target_rows[\u001b[38;5;241m0\u001b[39m][comparable_booleans]\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/KOOPAE/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/KOOPAE/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Master_Thesis/Bioinf/Code/philipp-trinh/KOOPOMICS/koopomics/model/model_loader.py:101\u001b[0m, in \u001b[0;36mKoopmanModel.forward\u001b[0;34m(self, input_vector, fwd, bwd)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predict_fwd\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     predict_bwd, predict_fwd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbwd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predict_bwd, predict_fwd\n",
      "File \u001b[0;32m~/Documents/Master_Thesis/Bioinf/Code/philipp-trinh/KOOPOMICS/koopomics/model/model_loader.py:73\u001b[0m, in \u001b[0;36mKoopmanModel.predict\u001b[0;34m(self, input_vector, fwd, bwd)\u001b[0m\n\u001b[1;32m     71\u001b[0m e_temp \u001b[38;5;241m=\u001b[39m e\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(bwd):\n\u001b[0;32m---> 73\u001b[0m     e_bwd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbwd_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43me_temp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding\u001b[38;5;241m.\u001b[39mdecode(e_bwd)\n\u001b[1;32m     76\u001b[0m     predict_bwd\u001b[38;5;241m.\u001b[39mappend(outputs)\n",
      "File \u001b[0;32m~/Documents/Master_Thesis/Bioinf/Code/philipp-trinh/KOOPOMICS/koopomics/model/koopmanANN.py:202\u001b[0m, in \u001b[0;36mLinearizingKoop.bwd_step\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbwd:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBackward operation is not implemented for this Operator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 202\u001b[0m e_lin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinearizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinearize\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m e_lin_bwd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkoop\u001b[38;5;241m.\u001b[39mbwdkoopOperation(e_lin) \n\u001b[1;32m    204\u001b[0m e_bwd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinearizer\u001b[38;5;241m.\u001b[39mdelinearize(e_lin_bwd)\n",
      "File \u001b[0;32m~/Documents/Master_Thesis/Bioinf/Code/philipp-trinh/KOOPOMICS/koopomics/model/koopmanANN.py:82\u001b[0m, in \u001b[0;36mFFLinearizer.linearize\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlinearize\u001b[39m(\u001b[38;5;28mself\u001b[39m, e):\n\u001b[0;32m---> 82\u001b[0m     e_lin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlin_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m e_lin\n",
      "File \u001b[0;32m~/miniconda3/envs/KOOPAE/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/KOOPAE/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/KOOPAE/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/KOOPAE/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/KOOPAE/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/KOOPAE/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m~/miniconda3/envs/KOOPAE/lib/python3.10/site-packages/torch/nn/modules/module.py:1675\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1666\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1668\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[1;32m   1669\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[1;32m   1670\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1673\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[1;32m   1674\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[0;32m-> 1675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1677\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "embedding_model = em.FF_AE([264,100,100,20], [20,100,100,264])\n",
    "operator_model = op.LinearizingKoop(linearizer=op.FFLinearizer([20,30,40], [40,30,20]), koop=op.InvKoop(latent_dim=40))\n",
    "\n",
    "LinKoopAE_model = ko.KoopmanModel(embedding=embedding_model, operator=operator_model)\n",
    "\n",
    "dyntargetinfo=[pregnancy_df, feature_list, sample_id, time_id]\n",
    "\n",
    "# Run training loop\n",
    "tr.train(LinKoopAE_model, dataloader, lr= 0.01, learning_rate_change=0.8, num_epochs=200, max_Kstep=15, weight_decay=0.01, model_name='TestingKoop', dyntargetinfo = dyntargetinfo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b3aa93-4360-4fb6-b947-a1d959f3474e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9427d05a-d5d0-4077-a9db-98bdb912f646",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(LinKoopAE_model.state_dict(), '/Users/daviddornig/Documents/Master_Thesis/Bioinf/Code/philipp-trinh/KOOPOMICS/model_states/TestingKOOP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0088b94b-100a-49b6-a9ed-2dd94c6032b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bwdM, fwdM = LinKoopAE_model.Kmatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826a8f17-a716-405e-aa34-2c422948ca39",
   "metadata": {},
   "outputs": [],
   "source": [
    "fwdM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d1f8b6-61ac-4f54-aa81-22070c364665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb380b2-bfd6-40dc-9911-5292a16fec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues, eigenvectors = np.linalg.eig(fwdM)\n",
    "print(\"Matrix:\")\n",
    "print(fwdM)\n",
    "print(\"\\nEigenvalues:\")\n",
    "print(eigenvalues)\n",
    "print(\"\\nEigenvectors:\")\n",
    "print(eigenvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4f3bc0-1420-4cd6-8c2b-02c84c121f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues, eigenvectors = np.linalg.eig(bwdM)\n",
    "print(\"Matrix:\")\n",
    "print(bwdM)\n",
    "print(\"\\nEigenvalues:\")\n",
    "print(eigenvalues)\n",
    "print(\"\\nEigenvectors:\")\n",
    "print(eigenvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87214b4-cf55-4d10-b472-e7acb7c48573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a sample matrix\n",
    "matrix = np.random.rand(40, 40)  # 10x10 matrix with random values\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Create a heatmap using seaborn\n",
    "sns.heatmap(matrix, annot=False, fmt=\".2f\", cmap='viridis')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Heatmap of the Given Matrix')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Rows')\n",
    "\n",
    "# Show the heatmap\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a442edd5-28b8-4d29-903b-fa990aa88851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Create a heatmap using seaborn\n",
    "sns.heatmap(fwdM, annot=False, fmt=\".2f\", cmap='viridis')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Heatmap of the Given Matrix')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Rows')\n",
    "\n",
    "# Show the heatmap\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd63455-c54c-4f7c-98cf-7ff17fbbc2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Create a heatmap using seaborn\n",
    "sns.heatmap(bwdM, annot=False, fmt=\".2f\", cmap='viridis')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Heatmap of the Given Matrix')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Rows')\n",
    "\n",
    "# Show the heatmap\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b03f9c-0e37-4a0b-a6b3-95c896a333ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d63418-ab7f-4cc4-87b3-c65ebfc9466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple identity model that returns input as output\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, input_size)  # A linear layer that learns a transformation\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Instantiate model, loss function, and optimizer\n",
    "model = SimpleModel(len(feature_list))\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Run training loop\n",
    "train(model, dataloader, criterion, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37e61a6-c360-4388-be75-e641b157ce8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
